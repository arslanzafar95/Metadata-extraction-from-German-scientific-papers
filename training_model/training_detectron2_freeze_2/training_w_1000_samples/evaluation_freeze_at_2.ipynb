{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation_freeze_at_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"r6j_4ylX01wM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":642},"executionInfo":{"status":"ok","timestamp":1596612823048,"user_tz":-120,"elapsed":21987,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"168c39a2-3139-412c-9526-0d0cd29d7819"},"source":["# install dependencies: (use cu101 because colab has CUDA 10.1)\n","!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n","Requirement already up-to-date: torch==1.5 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n","Requirement already up-to-date: torchvision==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n","Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-6ipqx6k7\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-6ipqx6k7\n","Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (49.2.0)\n","Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n","Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266462 sha256=f38ca1966c4438d17695caab7e0b044045761e3d806e86a373d1dda9408d9aef\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kpty241b/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Found existing installation: pycocotools 2.0\n","    Uninstalling pycocotools-2.0:\n","      Successfully uninstalled pycocotools-2.0\n","Successfully installed pycocotools-2.0\n","1.5.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wFigvYp0-z-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596612931180,"user_tz":-120,"elapsed":689,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"23699af8-bb07-410e-c628-9601a7a445bf"},"source":["# mount your gdrive folder\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M6vsR75H1Enq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596612935071,"user_tz":-120,"elapsed":453,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"7d625768-aff1-408d-ecef-e232878bf632"},"source":["%cd /content/drive/My Drive/ML_Application/freeze_at2_1000_samples\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ML_Application/freeze_at2_1000_samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qpqs7gbV2kuS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":799},"executionInfo":{"status":"ok","timestamp":1596612939808,"user_tz":-120,"elapsed":4181,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"6f7a8ad9-a994-4ec2-f6d0-201388ee1955"},"source":["# install detectron2:\n","!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n","Requirement already satisfied: detectron2==0.1.3 in /usr/local/lib/python3.6/dist-packages (0.1.3+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n","Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.1.1.post20200716)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.1.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.0.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.3.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2==0.1.3) (2.4.7)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (2.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.18.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (49.2.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_pqUw3pn2r1h","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596613242067,"user_tz":-120,"elapsed":715,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}}},"source":["# You may need to restart your runtime prior to this, to let your installation take effect\n","# Some basic setup:\n","# Setup detectron2 logger\n","\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","#setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6x2CtOr-2uhr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596613244525,"user_tz":-120,"elapsed":485,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"6f746d80-c7bb-44d9-fbcf-56864b043dff"},"source":["import os\n","import datetime\n","from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","\n","# create the output dir for the trained model\n","output_dir = os.path.join(\"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/output_freeze2\", \"20200804T1348\") #20200715T0954\n","# change the config in the .yaml document\n","print(output_dir)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/output_freeze2/20200804T1348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HcH8Vp3Z3xpe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596613250645,"user_tz":-120,"elapsed":806,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}}},"source":["\n","# Register a dataset in COCO’s json annotation format for instance detection, instance segmentation and keypoint detection. \n","from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/train/coco_train.json\", \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/train\")\n","register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/val/coco_val.json\", \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/val\")\n","register_coco_instances(\"my_dataset_test\", {}, \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/coco_test.json\", \"/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"9veuHMiH7Ojm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1596613251310,"user_tz":-120,"elapsed":426,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"24f6dcaf-1470-4bcc-884e-8b2a6717c57e"},"source":["from detectron2.data import DatasetCatalog, MetadataCatalog\n","\n","papers_metadata = MetadataCatalog.get(\"my_dataset_train\") #return the Metadata instance associated with this name\n","dataset_dicts = DatasetCatalog.get(\"my_dataset_train\") # Call the registered function and return dataset annotations"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FCLiPPaU3iPa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596613259881,"user_tz":-120,"elapsed":6403,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}}},"source":["cfg = get_cfg() #load default config\n","cfg.merge_from_file(output_dir + \"/train_config_freeze2.yaml\")\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n","# suppress overlap of bounding boxes by applying non-maximum suppression (NMS)\n","cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n","cfg.DATASETS.TEST = (\"my_dataset_val\", )\n","predictor = DefaultPredictor(cfg)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-FvwR634DwF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596613261727,"user_tz":-120,"elapsed":567,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"24d209a4-61ca-441f-c30d-2cb081aa4d8c"},"source":["predictor"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<detectron2.engine.defaults.DefaultPredictor at 0x7f9981e000b8>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"M2u7OZ5w68Sa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fU1TXYr72yCYr371_QqQTSVpCEiVtslv"},"executionInfo":{"status":"ok","timestamp":1596611840435,"user_tz":-120,"elapsed":214290,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"2e2eca6d-51f6-45c8-f503-294784042f6c"},"source":["trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","\n","from detectron2.utils.visualizer import ColorMode\n","dataset_dicts_val = DatasetCatalog.get(\"my_dataset_val\")\n","for d in dataset_dicts_val:    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=papers_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"3zV1nBvi6-vH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596611979892,"user_tz":-120,"elapsed":135043,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"52d8bcc7-9990-4bb4-fc8a-f05d35134865"},"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=output_dir)\n","val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n","inference_on_dataset(trainer.model, val_loader, evaluator)\n","# another equivalent way is to use trainer.test"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/05 07:17:25 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[08/05 07:17:25 d2.data.datasets.coco]: \u001b[0mLoaded 183 images in COCO format from /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/val/coco_val.json\n","\u001b[32m[08/05 07:17:25 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n","|  abstract  | 102          |  address   | 48           | affiliation | 129          |\n","|   author   | 183          |    date    | 186          |     doi     | 48           |\n","|   email    | 47           |  journal   | 138          |    title    | 183          |\n","|            |              |            |              |             |              |\n","|   total    | 1064         |            |              |             |              |\u001b[0m\n","\u001b[32m[08/05 07:17:25 d2.data.common]: \u001b[0mSerializing 183 elements to byte tensors and concatenating them all ...\n","\u001b[32m[08/05 07:17:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n","\u001b[32m[08/05 07:17:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 183 images\n","\u001b[32m[08/05 07:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/183. 0.7122 s / img. ETA=0:02:03\n","\u001b[32m[08/05 07:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 18/183. 0.7124 s / img. ETA=0:01:58\n","\u001b[32m[08/05 07:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 25/183. 0.7126 s / img. ETA=0:01:53\n","\u001b[32m[08/05 07:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 32/183. 0.7129 s / img. ETA=0:01:49\n","\u001b[32m[08/05 07:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 39/183. 0.7136 s / img. ETA=0:01:44\n","\u001b[32m[08/05 07:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 46/183. 0.7138 s / img. ETA=0:01:39\n","\u001b[32m[08/05 07:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 53/183. 0.7139 s / img. ETA=0:01:33\n","\u001b[32m[08/05 07:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 60/183. 0.7139 s / img. ETA=0:01:28\n","\u001b[32m[08/05 07:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 67/183. 0.7143 s / img. ETA=0:01:23\n","\u001b[32m[08/05 07:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 74/183. 0.7145 s / img. ETA=0:01:18\n","\u001b[32m[08/05 07:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 81/183. 0.7143 s / img. ETA=0:01:13\n","\u001b[32m[08/05 07:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 88/183. 0.7142 s / img. ETA=0:01:08\n","\u001b[32m[08/05 07:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 95/183. 0.7145 s / img. ETA=0:01:03\n","\u001b[32m[08/05 07:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 102/183. 0.7147 s / img. ETA=0:00:58\n","\u001b[32m[08/05 07:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 109/183. 0.7148 s / img. ETA=0:00:53\n","\u001b[32m[08/05 07:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 116/183. 0.7149 s / img. ETA=0:00:48\n","\u001b[32m[08/05 07:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 123/183. 0.7149 s / img. ETA=0:00:43\n","\u001b[32m[08/05 07:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 130/183. 0.7150 s / img. ETA=0:00:38\n","\u001b[32m[08/05 07:19:04 d2.evaluation.evaluator]: \u001b[0mInference done 137/183. 0.7149 s / img. ETA=0:00:33\n","\u001b[32m[08/05 07:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 144/183. 0.7149 s / img. ETA=0:00:28\n","\u001b[32m[08/05 07:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 151/183. 0.7150 s / img. ETA=0:00:23\n","\u001b[32m[08/05 07:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 158/183. 0.7152 s / img. ETA=0:00:18\n","\u001b[32m[08/05 07:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 165/183. 0.7152 s / img. ETA=0:00:13\n","\u001b[32m[08/05 07:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 172/183. 0.7152 s / img. ETA=0:00:07\n","\u001b[32m[08/05 07:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 179/183. 0.7154 s / img. ETA=0:00:02\n","\u001b[32m[08/05 07:19:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.989424 (0.724660 s / img per device, on 1 devices)\n","\u001b[32m[08/05 07:19:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:07 (0.715415 s / img per device, on 1 devices)\n","\u001b[32m[08/05 07:19:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[08/05 07:19:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/output_freeze2/20200804T1348/coco_instances_results.json\n","\u001b[32m[08/05 07:19:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.40s).\n","Accumulating evaluation results...\n","DONE (t=0.11s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n","\u001b[32m[08/05 07:19:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 24.517 | 28.510 | 26.785 | 3.737 | 28.859 | 36.465 |\n","\u001b[32m[08/05 07:19:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category   | AP     | category   | AP     | category    | AP     |\n","|:-----------|:-------|:-----------|:-------|:------------|:-------|\n","| abstract   | 92.216 | address    | 0.000  | affiliation | 14.908 |\n","| author     | 27.458 | date       | 10.088 | doi         | 0.000  |\n","| email      | 5.693  | journal    | 2.970  | title       | 67.323 |\n","Loading and preparing results...\n","DONE (t=0.02s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.49s).\n","Accumulating evaluation results...\n","DONE (t=0.11s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n","\u001b[32m[08/05 07:19:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 24.122 | 28.510 | 26.572 | 4.559 | 25.369 | 36.265 |\n","\u001b[32m[08/05 07:19:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n","| category   | AP     | category   | AP    | category    | AP     |\n","|:-----------|:-------|:-----------|:------|:------------|:-------|\n","| abstract   | 92.979 | address    | 0.000 | affiliation | 12.654 |\n","| author     | 28.049 | date       | 8.986 | doi         | 0.000  |\n","| email      | 6.188  | journal    | 2.211 | title       | 66.033 |\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('bbox',\n","              {'AP': 24.517325168767066,\n","               'AP-abstract': 92.21566320760236,\n","               'AP-address': 0.0,\n","               'AP-affiliation': 14.908062234794908,\n","               'AP-author': 27.45813307851199,\n","               'AP-date': 10.088072025593364,\n","               'AP-doi': 0.0,\n","               'AP-email': 5.693069306930694,\n","               'AP-journal': 2.9702970297029703,\n","               'AP-title': 67.32262963576729,\n","               'AP50': 28.50971707683703,\n","               'AP75': 26.78507217190422,\n","               'APl': 36.46487431825471,\n","               'APm': 28.859280605103976,\n","               'APs': 3.7370737073707367}),\n","             ('segm',\n","              {'AP': 24.122279964323614,\n","               'AP-abstract': 92.97915481146498,\n","               'AP-address': 0.0,\n","               'AP-affiliation': 12.654375556603279,\n","               'AP-author': 28.04883530463537,\n","               'AP-date': 8.985622946531107,\n","               'AP-doi': 0.0,\n","               'AP-email': 6.188118811881188,\n","               'AP-journal': 2.211221122112211,\n","               'AP-title': 66.0331911256844,\n","               'AP50': 28.50971707683703,\n","               'AP75': 26.571982079826228,\n","               'APl': 36.265001079857576,\n","               'APm': 25.3691339675362,\n","               'APs': 4.559405940594059})])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"RQRm7s1c7dMt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eafR9mgO-Lbq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVhhp9d3_Ays","colab_type":"text"},"source":["Making predictions on the test set"]},{"cell_type":"code","metadata":{"id":"XDK7-anQ_Dzr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596614070084,"user_tz":-120,"elapsed":174626,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"db1a5053-a165-4c82-f4c1-f970bbc28eb3"},"source":["trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","\n","from detectron2.utils.visualizer import ColorMode\n","dataset_dicts_test = DatasetCatalog.get(\"my_dataset_test\")\n","\n","for d in dataset_dicts_test:    \n","    im = cv2.imread(d[\"file_name\"])\n","    print(d[\"file_name\"][:-5])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=papers_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2.imwrite(d[\"file_name\"][:-5] + \"_test_nms.png\", v.get_image()[:, :, ::-1])\n","    #cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\u001b[32m[08/05 07:51:37 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/05 07:51:37 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[08/05 07:51:37 d2.data.datasets.coco]: \u001b[0mLoaded 547 images in COCO format from /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/train/coco_train.json\n","\u001b[32m[08/05 07:51:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 547 images left.\n","\u001b[32m[08/05 07:51:37 d2.data.common]: \u001b[0mSerializing 547 elements to byte tensors and concatenating them all ...\n","\u001b[32m[08/05 07:51:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n","\u001b[32m[08/05 07:51:37 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[08/05 07:51:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/05 07:51:39 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[08/05 07:51:39 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/coco_test.json\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_282\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_179\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_13\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_293\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/11448\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_242\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_299\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_167\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_148\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_274\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_16\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_135\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_244\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_256\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_1\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_96\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_293\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_104\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/12797\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_288\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_201\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_97\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/17492\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_225\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_245\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_289\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_143\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_144\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_102\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_258\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_147\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_230\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_39\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_79\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_80\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_167\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_107\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_146\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_115\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_189\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_27\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_169\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_230\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_9\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_113\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_202\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_175\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_177\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_67\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_241\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_232\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_70\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_194\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_4\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_139\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_271\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_160\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_87\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_119\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_74\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_67\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_206\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_203\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_219\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_187\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_16\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_166\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_226\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_144\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_193\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_104\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/10454\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_126\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_251\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_6\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_33\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_243\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_124\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_4\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_287\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_72\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_78\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_211\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_125\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_220\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_59\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_191\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_159\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_160\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_249\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_272\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_268\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_289\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_12\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_179\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_134\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_297\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_209\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_130\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_91\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_278\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_52\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_179\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_206\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_180\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_162\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_17\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/19396\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_196\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_158\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_257\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_90\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_117\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_113\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_149\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_130\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_174\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_174\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_192\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/22006\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_265\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_95\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_243\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_183\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_219\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_163\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_217\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/31474\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_74\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_287\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_156\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_91\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_28\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_71\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_12\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_81\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_5\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_83\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_3\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_205\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/11164\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_260\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_248\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_157\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_132\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_1\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_111\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_70\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_277\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_233\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_74\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_70\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_282\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_88\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_249\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_257\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_177\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_26\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_15\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_217\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_240\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_168\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_188\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_187\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_262\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_212\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_266\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_191\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_72\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_158\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_221\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_25\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_75\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_86\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_88\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/11190\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_278\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_236\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/48259_139\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_283\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_164\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_84\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_57\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/4336_225\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_56\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_87\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/42768_93\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_195\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_146\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_44\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_72\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_254\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/45544_294\n","/content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/44475_22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RAiPNQBW_tNh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596614214886,"user_tz":-120,"elapsed":144772,"user":{"displayName":"Timo Hartmann","photoUrl":"","userId":"16517026155215548283"}},"outputId":"59ffd574-fdcf-4403-8602-4ca4315e853b"},"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=output_dir)\n","val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n","inference_on_dataset(trainer.model, val_loader, evaluator)\n","# another equivalent way is to use trainer.test"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/05 07:54:30 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[08/05 07:54:30 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/data/test/coco_test.json\n","\u001b[32m[08/05 07:54:30 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n","|  abstract  | 183          |  address   | 4            | affiliation | 344          |\n","|   author   | 307          |    date    | 145          |     doi     | 137          |\n","|   email    | 2            |  journal   | 86           |    title    | 194          |\n","|            |              |            |              |             |              |\n","|   total    | 1402         |            |              |             |              |\u001b[0m\n","\u001b[32m[08/05 07:54:30 d2.data.common]: \u001b[0mSerializing 194 elements to byte tensors and concatenating them all ...\n","\u001b[32m[08/05 07:54:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n","\u001b[32m[08/05 07:54:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 194 images\n","\u001b[32m[08/05 07:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/194. 0.7180 s / img. ETA=0:02:12\n","\u001b[32m[08/05 07:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 18/194. 0.7200 s / img. ETA=0:02:08\n","\u001b[32m[08/05 07:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 25/194. 0.7186 s / img. ETA=0:02:02\n","\u001b[32m[08/05 07:54:54 d2.evaluation.evaluator]: \u001b[0mInference done 32/194. 0.7195 s / img. ETA=0:01:58\n","\u001b[32m[08/05 07:54:59 d2.evaluation.evaluator]: \u001b[0mInference done 39/194. 0.7203 s / img. ETA=0:01:53\n","\u001b[32m[08/05 07:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 46/194. 0.7206 s / img. ETA=0:01:48\n","\u001b[32m[08/05 07:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 53/194. 0.7206 s / img. ETA=0:01:42\n","\u001b[32m[08/05 07:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 60/194. 0.7209 s / img. ETA=0:01:37\n","\u001b[32m[08/05 07:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 67/194. 0.7213 s / img. ETA=0:01:32\n","\u001b[32m[08/05 07:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 74/194. 0.7212 s / img. ETA=0:01:27\n","\u001b[32m[08/05 07:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 81/194. 0.7212 s / img. ETA=0:01:22\n","\u001b[32m[08/05 07:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 88/194. 0.7214 s / img. ETA=0:01:17\n","\u001b[32m[08/05 07:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 95/194. 0.7215 s / img. ETA=0:01:12\n","\u001b[32m[08/05 07:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 102/194. 0.7215 s / img. ETA=0:01:07\n","\u001b[32m[08/05 07:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 109/194. 0.7214 s / img. ETA=0:01:02\n","\u001b[32m[08/05 07:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 116/194. 0.7216 s / img. ETA=0:00:57\n","\u001b[32m[08/05 07:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 123/194. 0.7216 s / img. ETA=0:00:51\n","\u001b[32m[08/05 07:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 130/194. 0.7217 s / img. ETA=0:00:46\n","\u001b[32m[08/05 07:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 137/194. 0.7218 s / img. ETA=0:00:41\n","\u001b[32m[08/05 07:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 144/194. 0.7219 s / img. ETA=0:00:36\n","\u001b[32m[08/05 07:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 151/194. 0.7220 s / img. ETA=0:00:31\n","\u001b[32m[08/05 07:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 158/194. 0.7221 s / img. ETA=0:00:26\n","\u001b[32m[08/05 07:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 165/194. 0.7222 s / img. ETA=0:00:21\n","\u001b[32m[08/05 07:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 172/194. 0.7222 s / img. ETA=0:00:16\n","\u001b[32m[08/05 07:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 179/194. 0.7222 s / img. ETA=0:00:10\n","\u001b[32m[08/05 07:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 186/194. 0.7221 s / img. ETA=0:00:05\n","\u001b[32m[08/05 07:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 193/194. 0.7221 s / img. ETA=0:00:00\n","\u001b[32m[08/05 07:56:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.361008 (0.732069 s / img per device, on 1 devices)\n","\u001b[32m[08/05 07:56:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:16 (0.722125 s / img per device, on 1 devices)\n","\u001b[32m[08/05 07:56:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[08/05 07:56:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/My Drive/ML_Application/freeze_at2_1000_samples/output_freeze2/20200804T1348/coco_instances_results.json\n","\u001b[32m[08/05 07:56:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.47s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n","\u001b[32m[08/05 07:56:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n","|:------:|:------:|:------:|:-----:|:-----:|:------:|\n","| 15.793 | 19.122 | 17.655 | 0.757 | 7.073 | 26.071 |\n","\u001b[32m[08/05 07:56:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category   | AP     | category   | AP    | category    | AP     |\n","|:-----------|:-------|:-----------|:------|:------------|:-------|\n","| abstract   | 71.971 | address    | 0.000 | affiliation | 0.000  |\n","| author     | 7.212  | date       | 5.380 | doi         | 0.000  |\n","| email      | 0.000  | journal    | 5.646 | title       | 51.929 |\n","Loading and preparing results...\n","DONE (t=0.02s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.70s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.110\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n","\u001b[32m[08/05 07:56:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n","|:------:|:------:|:------:|:-----:|:-----:|:------:|\n","| 15.607 | 19.234 | 17.260 | 0.734 | 6.752 | 25.765 |\n","\u001b[32m[08/05 07:56:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n","| category   | AP     | category   | AP    | category    | AP     |\n","|:-----------|:-------|:-----------|:------|:------------|:-------|\n","| abstract   | 72.267 | address    | 0.000 | affiliation | 0.000  |\n","| author     | 7.091  | date       | 5.182 | doi         | 0.000  |\n","| email      | 0.000  | journal    | 5.662 | title       | 50.266 |\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('bbox',\n","              {'AP': 15.79309532428064,\n","               'AP-abstract': 71.97062024140274,\n","               'AP-address': 0.0,\n","               'AP-affiliation': 0.0,\n","               'AP-author': 7.212214264898999,\n","               'AP-date': 5.379537953795379,\n","               'AP-doi': 0.0,\n","               'AP-email': 0.0,\n","               'AP-journal': 5.646047912233869,\n","               'AP-title': 51.92943754619478,\n","               'AP50': 19.12157953814279,\n","               'AP75': 17.655336396168618,\n","               'APl': 26.070536571816668,\n","               'APm': 7.0731974154346915,\n","               'APs': 0.7567006700670067}),\n","             ('segm',\n","              {'AP': 15.60748171189698,\n","               'AP-abstract': 72.26712121014616,\n","               'AP-address': 0.0,\n","               'AP-affiliation': 0.0,\n","               'AP-author': 7.090514485368058,\n","               'AP-date': 5.1815181518151805,\n","               'AP-doi': 0.0,\n","               'AP-email': 0.0,\n","               'AP-journal': 5.661699738172657,\n","               'AP-title': 50.266481821570785,\n","               'AP50': 19.23409592521127,\n","               'AP75': 17.25961468775251,\n","               'APl': 25.76540182255079,\n","               'APm': 6.751565151885799,\n","               'APs': 0.7343234323432343})])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"9ZszkM_nCmTc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
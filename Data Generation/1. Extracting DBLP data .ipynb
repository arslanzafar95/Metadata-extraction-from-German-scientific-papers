{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DBLP xml is above 3 GB, so I read some data from dblp.xml here and parsed it using 'https://jsonformatter.org/xml-parser', \n",
    "and saved the Output xml in new file 'dblps.xml '''\n",
    "\n",
    "# Link to download dblp.xml --> https://dblp.uni-trier.de/xml/dblp.xml.gz\n",
    "\n",
    "fname = open(\"dblp.xml\",'r')\n",
    "counter = 0\n",
    "for line in fname:\n",
    "    # replacing special characters in dblp xml\n",
    "    line=line.replace(';','').replace('&ecirc','ê').replace('&eacute','é').replace('&egrave','è').replace('&Euml','Ë').replace('&Ecirc','Ê').replace('&Eacute','É').replace('&Egrave','È').replace('&ccedil','ç').replace('&Ccedil','Ç').replace('&szlig','ß').replace('&aelig','æ').replace('&AElig','Æ').replace('&aring','å').replace('&auml','ä').replace('&atilde','ã').replace('&acirc','â').replace('&aacute','á').replace('&agrave','à').replace('&Aring','Å').replace('&Auml','Ä').replace('&Atilde','Ã').replace('&Acirc','Â').replace('&Aacute','Á').replace('&Agrave','À').replace('&euml','ë').replace('&Iacute','Í').replace('&Icirc','Î').replace('&Iuml','Ï').replace('&igrave','ì').replace('&iacute','í').replace('&icirc','î').replace('&iuml','ï').replace('&Ntilde','Ñ').replace('&ntilde','ñ').replace('&Ograve','Ò').replace('&Oacute','Ó').replace('&Ocirc','Ô').replace('&Otilde','Õ').replace('&Ouml','Ö').replace('&ograve','ò').replace('&oacute','ó').replace('&ocirc','ô').replace('&otilde','õ').replace('&ouml','ö').replace('&Oslash','Ø').replace('&oslash','ø').replace('&Ugrave','Ù').replace('&Uacute','Ú').replace('&Ucirc','Û').replace('&Uuml','Ü').replace('&ugrave','ù').replace('&uacute','ú').replace('&ucirc','û').replace('&uuml','ü').replace('&Yacute','Ý').replace('&yacute','ý').replace('&yuml','ÿ') \n",
    "    print (line)\n",
    "    counter = counter+1\n",
    "    if counter == 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opening new 'dblps.xml' file that I created\n",
    "fname = open(\"dblps.xml\",'r')\n",
    "fname.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('dblps.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = []\n",
    "\n",
    "# finding article tags in xml \n",
    "for article in root.findall('article'):\n",
    "    list_all = []\n",
    "    \n",
    "    # finding author,title tags and so on... and create a list\n",
    "    authors = article.findall('author')\n",
    "    author_lst=[]\n",
    "    for author in authors:\n",
    "        author_value = author.text\n",
    "        author_lst.append(author_value)\n",
    "    list_all.append(author_lst)\n",
    "    \n",
    "    \n",
    "    titles = article.findall('title')\n",
    "    title_lst=[]\n",
    "    for title in titles:\n",
    "        title_value = title.text\n",
    "        title_lst.append(title_value)\n",
    "    list_all.append(title_lst)\n",
    "    \n",
    "    \n",
    "    journals = article.findall('journal')\n",
    "    journal_lst=[]\n",
    "    for journal in journals:\n",
    "        journal_value = journal.text\n",
    "        journal_lst.append(journal_value)\n",
    "    list_all.append(journal_lst)\n",
    "    \n",
    "    \n",
    "    years = article.findall('years')\n",
    "    year_lst=[]\n",
    "    for year in years:\n",
    "        year_value = year.text\n",
    "        year_lst.append(year_value)\n",
    "    list_all.append(year_lst)\n",
    "    \n",
    "    \n",
    "    dois = article.findall('ee')\n",
    "    try:\n",
    "        aa=dois[0]\n",
    "    except:\n",
    "        dois = article.findall('url')\n",
    "    doi_lst=[]\n",
    "    for doi in dois:\n",
    "        doi_value = doi.text\n",
    "        doi_lst.append(doi_value)\n",
    "    list_all.append(doi_lst)\n",
    "    \n",
    "    \n",
    "    publishers = article.findall('publisher')\n",
    "    publisher_lst=[]\n",
    "    for publisher in publishers:\n",
    "        publisher_value = publisher.text\n",
    "        publisher_lst.append(publisher_value)\n",
    "    list_all.append(publisher_lst)\n",
    "    \n",
    "   \n",
    "    article_data.append(list_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save article data in dataframe\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns={'author','title','journal','year','doi','publisher'})\n",
    "\n",
    "index=0\n",
    "for article in article_data:\n",
    "    df.loc[index,'author']= article[0]\n",
    "    df.loc[index,'title']= article[1]\n",
    "    df.loc[index,'journal']= article[2]\n",
    "    df.loc[index,'year']= article[3]\n",
    "    df.loc[index,'doi']= article[4]\n",
    "    df.loc[index,'publisher']= article[5]\n",
    "    index=index+1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df.to_excel(\"dataframe.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
